# 科研简述

在研究生一年级期间，除了课业的任务之外，我还在周皓老师的指导下进行了多项关于资产定价的研究工作，利用大数据技术与算法处理金融资产数据，内容包括股票聚类算法，资产数据结构研究以及金融显著性研究。接下来我将逐一简述。

## C-Lasso

C-Lasso 是 Liangjun Su, Zhentao Shi, and Peter C. B. Phillips 在 2016 年发表于 Econometrica 上的工作。该方法在原有 lasso 方法的基础上进行了改进，能够同时实现分类和得到一致估计。通过综合运用优化知识和基于数据统计性质的推断方法，C-Lasso 为股票市场提供了一种新的分析工具，旨在揭示资产之间的关联性和共同特征，探索资产之间的结构，接下来我将对该方法进行简述，并给出其在股票市场中的应用。

### Methodology

对于任意 panel 数据集，$\{(y_{it},x_{it})\}\text{ for }i=1,\ldots,N\text{ and }t=1,\ldots,T,$，通常可以通过拟极大似然估计法 (quasi-maximum likelihood estimation, QMLE) 进行估计，该方法求解以下优化问题

$$
\begin{equation}
    \min_{\{\beta_i,\mu_i\}}\frac1{NT}\sum_{i=1}^N\sum_{t=1}^T\psi(w_{it};\beta_i,\mu_i).
\end{equation}
$$

$-\psi(w_{it};\beta_i,\mu_i)$ 代表 $y_{i,t}$ 在给定 $x_{i,t}$ 时的伪真实 (pseudo-true) 条件密度函数。

对于线性面板回归

$$
\begin{equation}
    y_{it}=\beta_i^{0\prime}x_{it}+\mu_i^0+\varepsilon_{it},
\end{equation}
$$

其中 $x_{i,t}$ 是 $p\times1$ 维的自变量，$\beta_i$ 是 $p\times1$ 维的估计系数，$\mu_i$ 是个体固定效应，$\varepsilon_{i,t}$ 是均值为零的方差扰动项。该式拟极大似然估计量为：$\psi(w_{it};\beta_i,\mu_i)=\frac12(y_{it}-\beta_i^{\prime}x_{it}-\mu_i)^2, w_{it}=(y_{it},x_{it}^{\prime})^{\prime}$。

传统估计面板数据的做法分为两种，一种认为 $\beta_i$ 对于所有变量一致，仅由 $\mu_i$ 来表征个体间的异质性；另一种假定 $\beta_i$ 对于所有个体均不相同，需要单独估计每个参数。显而易见，这两种方法均有其局限性。

受 group Lasso 的启发，Su 等人 (2016) 提出了通过轮廓似然函数 (Penalized Profile Likelihood, PPL) 来得到带有分组估计的 $\beta_i$。

$$
\begin{align}
    Q_{1,NT}(\boldsymbol{\beta})=\frac1{NT}\sum_{i=1}^N\sum_{t=1}^T\psi\big(w_{it};\boldsymbol{\beta}_i,\hat{\boldsymbol{\mu}}_i(\boldsymbol{\beta}_i)\big), \\
    Q_{1NT,\lambda_1}^{(K_0)}(\boldsymbol{\beta},\boldsymbol{\alpha})=Q_{1,NT}(\boldsymbol{\beta})+\frac{\lambda_1}N\sum_{i=1}^N\prod_{k=1}^{K_0}\|\beta_i-\alpha_k\|,
\end{align}
$$

其中 $\begin{aligned}\hat{\mu}_i(\beta_i)=\arg\min_{\mu_i}\frac1T\sum_{t=1}^T\psi(w_{it};\beta_i,\mu_i).\end{aligned}$，$\lambda_1=\lambda_{1NT}$ 是超参数。

**累加-累乘形式的惩罚项**是能够实现分组的原因，同时也是 Su 等人 (2016) 的创新之处。累加的形式不难理解，而累乘项是因为 $\beta_i^0$ 有可能被分到任何一组 $\alpha_0$ 内，一旦确定分组，则该系数对应的惩罚项为零。基础的 Lasso 是通过将一些估计值压缩至零来实现稀疏性，主要目标是选择有价值的变量。而 C-Lasso 的主要目标是实现个体之间的**分组关系**。

该方法在lasso的基础上实现了分类，因此也称之为 *classifier-Lasso*。最终的分类结果如下：

$$\begin{equation}
\beta_i^0=\sum_{k=1}^{K_0}\alpha_k^0\mathbf{1}\{i\in G_k^0\}.
\end{equation}
$$

其中 $\alpha_j^0\neq\alpha_k^0\text{ for any }j\neq k,\bigcup_{k=1}^{K_0}G_k^0=\{1,2,\ldots,N\},\mathrm{~and~}G_k^0\cap G_j^0=\emptyset \text{ for any }j\neq k $。

### Application In Finance

通常我们认为，资产的超额预期收益率与与因子风险溢价之间满足如下关系

$$
\begin{equation}
    E[R_{i}^e] = \alpha_i + \beta_i' \lambda,
\end{equation}
$$

其中 $R_{i}^e$ 代表资产的超额收益，$\beta_i$ 为资产 $i$ 的 K 维因子暴露向量，$\lambda$ 为 $K$ 维因子风险溢价。该模型中包含的因子代表了收益率的一种结构：如果一个资产在因子上的暴露 $\beta_i$ 越高，那么它的预期收益 $E[R_{i}^e]$ 也会更高。

自 Fama 和 French (1993) 以来，学术界往往通过添加因子数量的方式来选择最优的因子结构，而通过 C-Lasso，可以实现另一种文献中**从未被探索过**的方式。

$$
\begin{equation}
    E[R_{i}^e] = \alpha_i + \left( \beta_1,\beta_2 ,\cdots \beta_k \right)
    \begin{pmatrix}
    \lambda_1 \\
    \lambda_1^2 \\
    \vdots \\
    \lambda_1^k
    \end{pmatrix}
\end{equation}
$$

即，**不同资产对于同一因子，有着不同水平的风险溢价**。这一假设虽然没有被正式提出过，但是其思想仍有迹可循。Goyal 等 (2008) 提出存在影响所有股票的 common pervasive factors 以及仅影响部分股票的 group-specific pervasive factors，并在纽约证券交易所以及纳斯达克市场分别估计出了一个 specific factors。Lettau 和 Pelger (2020) 也估计出了仅影响一部分股票的 weak factor，并指出该类因子的发现能够显著提高有效边界。现有文献仅仅是对于该思路一个初步的尝试，而没有系统地提出框架，并且，该方法估计出的因子通常为 latent factor，可解释性较弱。而通过 C-Lasso，可以较为全面的实现该方法论，**对现有文献产生革新**。

该项研究目前有了初步的结果，已经能够实现稳定分组，在博士期间我计划继续对分组结果进行深入研究。


## 流形 Manifold

除了 C-Lasso，我还进行了有关机器学习方面的研究。该研究意在探索数据的流形结构，并通过 Meta-Learning，Incremental Learning 等算法提取数据中的信息。

近年来，越来越多的研究将机器学习算法应用于金融资产数据，并取得了一定的成果。然而，其中大多数研究没有考虑数据本身的结构，在图像处理领域已经表明，当考虑数据本身的结构时，能够显著地提高模型表现。具体来说，大多数算法，如卷积神经网络 (Convolutional Neural Network, CNN)，只是武断地将数据在欧氏空间中进行各种变换与操作。

忽略数据本身的信息，会很大程度上伤害模型的表现。一方面，人脸数据属于高维数据，而高位的欧氏空间可由低维的黎曼流形空间表征；另一方面，Euclidean Distance 往往不适用于高维情形，因为高维特征中并非所有维度都同样重要，或是表征同样多的信息量，在这种情况下，往往黎曼流形空间中的 Geodesic Distance 更加适合。

尽管我们认为数据中存在流形结构，但大多数算法都是应用于欧氏空间，因此需要将流形空间转化为欧氏空间进行操作。这一步转化是通过计算流形空间的切平面得到的，切平面作为流形空间的局部拟合，体现了从流形空间到欧氏空间的映射过程。

在金融中，股票特征、定价因子均是高维的，相似地，，因此，本研究实际上试图**从流形空间的角度解释 Factor Zoo** 的问题。尽管近年来许多研究者将各类算法应用于金融数据，但其均没有考虑用流形空间表征股票数据。本研究有望填补这一空白。

通常，我们会将许多流形空间做笛卡尔积形成积流形 (product manifold)，积流形有着更高的灵活度，能够拟合更加复杂的数据结构。

当我们想要在黎曼流形空间中应用，我们需要得到黎曼流形空间的**曲率** (curvature) ，特别地，当黎曼流形空间中曲率为零时，则退化为欧氏空间。这时就需要应用机器学习算法中的 Meta-Learning 来从数据中学习潜在的黎曼流行空间维度。Meta-Learning 的核心概念是 “Learn how to learn” ，因此具有很强的泛化能力，能够快速地根据不同任务、不同数据拟合出对应的结构。

**流形结构定义及度量**如下：

一个 $d$ 维、曲率为 $K$ 的曲率空间表示为 $\mathcal{M}_{K}^{d}$，对于 $u\in\mathcal{M}_{K}^{d}$，其切平面定义为 $T_{\boldsymbol{u}}\mathcal{M}_{K}^{d}$。

*内积*：对于 $\boldsymbol{q},s\in T_{\boldsymbol{u}}\mathcal{M}_{K}^{d}$，其内积定义为

$$
\begin{equation}
    \langle q,s\rangle_{\boldsymbol{u}}=(\lambda_{\boldsymbol{u}}^{K})^{2}\langle\boldsymbol{q},\boldsymbol{s}\rangle_{2},
\end{equation}
$$

其中 $\lambda_u^K=2/(1+K\|u^2\|)$ 是 conformal factor，$\left<\cdot,\cdot\right>_{2}$ 代表欧氏空间的内积操作。

*加法*：对于 $x,y\in\mathcal{M}_K^d$，加法定义为

$$
\begin{equation}
    x\oplus_K\boldsymbol{y}=\frac{(1-2K\langle\boldsymbol{x},\boldsymbol{y}\rangle_2-K\|\boldsymbol{y}\|^2)\boldsymbol{x}+(1+K\|\boldsymbol{x}\|^2)\boldsymbol{y}}{1-2K\langle\boldsymbol{x},\boldsymbol{y}\rangle_2+K^2\|\boldsymbol{x}\|^2\|\boldsymbol{y}\|^2}.
\end{equation}
$$

*距离度量*：对于 $x,y\in\mathcal{M}_K^d$，距离定义为

$$
\begin{equation}
    d(\boldsymbol{x},\boldsymbol{y})=\frac2{\sqrt{|K|}}\tan_K^{-1}(\sqrt{|K|}\cdot\|-\boldsymbol{x}\oplus_K\boldsymbol{y}\|).
\end{equation}
$$

*指数映射* (Exponential Map)：指数映射指的是将向量 $q$ 从切平面映射到流形空间，

$$
\begin{equation}
    \exp_{\boldsymbol{u}}^K(\boldsymbol{q})=\boldsymbol{u}\oplus_K\Bigg(\tan_K(\sqrt{|K|}\frac{\lambda_{\boldsymbol{u}}^K\|\boldsymbol{q}\|}{2})\frac{q}{\sqrt{|K|}\cdot\|\boldsymbol{q}\|}\Bigg).
\end{equation}
$$

*对数映射* (Logarithmic Map)：对数映射与指数映射相反，指的是将向量 $x$ 从流形空间映射到切平面，

$$
\begin{equation}
    \log_{\boldsymbol{u}}^{K}(\boldsymbol{x})=\frac{2}{\sqrt{|K|}\lambda_{\boldsymbol{u}}^{K}}\tan_{K}^{-1}(\sqrt{|K|}\cdot\|-u\oplus_{K}\boldsymbol{x}\|)\frac{-\boldsymbol{u}\oplus_{K}\boldsymbol{x}}{\|-\boldsymbol{u}\oplus_{K}\boldsymbol{x}\|}.
\end{equation}
$$

*正交投影* (Orthogonal Projection)：正交投影将欧式向量 $z$ 投影到切平面上，

$$
\begin{equation}
    \left.\operatorname{proj}_{\boldsymbol{u}}^{K}(z)=\left\{\begin{array}{l}\boldsymbol{z}-\langle\boldsymbol{u},\boldsymbol{z}\rangle_{2}\boldsymbol{u},\text{if }K\geq0\\\left(1/(\lambda_{\boldsymbol{u}}^{K})^{2}\right)\boldsymbol{z},\text{ if }K<0\end{array}\right.\right..
\end{equation}
$$

*积流形*：对于子流形 $\mathcal{M}_1,\ldots,\mathcal{M}_m$，其笛卡尔积定义为

$$
\begin{equation}
    \mathcal{M}_{p}: = \times_{j=1}^m\mathcal{M}_j.
\end{equation}
$$

目前代码搭建已经基本完成，下一步研究神经网络在流形空间中与数据的结合。

## Fourier Transformation for Finance Saliency


### 傅里叶变换

在处理图像的显著性问题时，我们需要对图像数据进行傅里叶变换，从时域转化为频域。傅里叶变换后得到的频率，振幅与相位均可以帮助我们识别图像中的显著性。在这三者之间，Li 等 (2015) 表明相位的正负对于显著性来说是最重要的。其背后的机理在于，对数据 $I$ 进行傅里叶变换后，

$$
\begin{equation}
    F(u,v)=\sum_{x=0}^{N-1}\sum_{y=0}^{N-1}I(x,y)e^{i\theta},\theta=\frac{-2\pi(ux+vy)}N,
\end{equation}
$$

$F(u,v)$ 实部与虚部可以写为如下形式：

$$
\begin{align}
    \begin{gathered}
    \Re(u,v)=\sum_{\cos\theta\geq0}\operatorname{cos}\theta I(x,y)+\sum_{\operatorname{cos}\theta<0}\operatorname{cos}\theta I(x,y), \\
    \begin{aligned}\Im(u,v)=\sum_{\sin\theta\geq0}\sin\theta I(x,y)+\sum_{\sin\theta<0}\sin\theta I(x,y).\end{aligned} 
    \end{gathered}
\end{align}
$$

进一步地，实部与虚部能够通过一些 template 表示：

$$
\begin{equation}
    \begin{aligned}\Re(u,v)&=\left\langle I\otimes\mathcal{T}_{uv}^{\Re+}\right\rangle-\left\langle I\otimes\mathcal{T}_{uv}^{\Re-}\right\rangle,\\\Im(u,v)&=\left\langle I\otimes\mathcal{T}_{uv}^{\Im+}\right\rangle-\left\langle I\otimes\mathcal{T}_{uv}^{\Im-}\right\rangle,\end{aligned}
\end{equation}
$$

其中，

$$
\begin{align}
\begin{gathered}
    \mathcal{T}_{uv}^{\Re+}(x,y) =\max(\cos\theta,0), \\
    \mathcal{T}_{uv}^{\Im+}(x,y) =\max(\sin\theta,0), \\
    \mathcal{T}_{uv}^{\Re-}(x,y) =\max(-\cos\theta,0), \\
    \mathcal{T}_{uv}^{\Im-}(x,y) =\max(-\sin\theta,0). 
\end{gathered}
\end{align}
$$

通过这种方式将傅里叶变换的结果重新表示后，从大量的实证中，能够清楚地看到**相位为正**时，总是对应着图像中显著的部分，而负相位往往对应非显著的部分。

### Finance Saliency

这背后的原理，是**对比**。对比之下，才会分出正负。在金融中，以构建因子为例，Long-short 也是对比，根据特征排序后，将强侧的组合与弱侧的组合一对比，也就形成了因子。如果脱离因子的范畴，而看向整个股票市场，在股票市场中也常常出现结构性行情，即仅有部分股票上涨，而另一部分股票上涨幅度极为微弱，甚至下跌，例如大小盘风格的切换。

在金融中，这些对比同样可以体现出 Saliency，那么就可以尝试通过傅里叶变换来表示其背后的逻辑。毫无疑问，上涨的股票代表是重要的股票，而根据傅里叶变换后相位的表征，就可以探究这些上涨的股票的规律。

目前，傅里叶变换部分的代码已经搭建完成，并得到了初步的分解结果，下一步打算继续尝试多种分解的可能性，例如目前是对月频数据进行分解，还需要对日频进行分解尝试，或是当前是对个股进行傅里叶分解，那么对投资组合进行傅里叶变换也值得尝试。


## 孙宁的工作

研究方向：微观经济理论；拍卖机制设计；市场机制设计；博弈理论

【2006Eca】：该文将不可分 objects 分成两个集合 $S_1, S_2$，提出了新的 preference condition，在该 condition 推导出的 competitive equilibrium 下，能够同时包括 substitutes 和 complements。当 $x\in S_1 \text{ and } y \in S_2$ 时，二者为 complement，当 $x,y \in S_1 \text{ or } x,y \in S_2$ 时，二者为 substitute。例如，工人和机器为 complement，而工人之间与机器之间为 substitute。

【2009Eca】： 文章提出了一种新的 Walrasian tâtonnemen 过程。存在两个集合，many buyers 将在同种集合内的物品视为替代品，而将不同集合内的物品视为互补品。在每一轮的拍卖过程中，seller 会给出价格，buyer report their demand，文章证明了，在有限轮内，该过程就会收敛。

【2014JPE】：文章提出了一种高效且激励兼容的动态拍卖方法，用于销售多种互补商品。通过动态调整价格，拍卖能够使竞标者真实出价，实现高效分配，并为每个竞标者提供广义的ickrey-Clarke-Groves payment。

【2020AER】：在工作匹配中，雇主经常面临各种类型的约束。本文研究了对雇主允许雇佣的员工集合施加的任意约束条件，并探讨了这些约束条件对雇主收入函数的影响。

【2023RES】：


## 总结

在研究生一年级期间，我探索了各个领域的知识，我不敢掉以轻心，对每一个领域的内容都 ”如临大敌“，尽可能地做到细致，认真而好奇地面对每一个新鲜的知识点。学到后来，我逐渐有一种感觉，这些知识背后，有许多共通之处。各式各样的研究，都在挖掘、理解事物的本质。如果有机会继续深造，我相信尽管这三项研究看似方法论天差地别，最后我也一定能接近其背后原理所隐含的相似之处。

研一的时间匆匆而逝，转眼间，自己作为一个刚刚入学的新生，已经开始申请博士了。一年多的时间过去，回过头看，有时不禁惊讶于自己竟学了如此多的知识。学习知识的过程对我来说并不枯燥，我也并未因为知识的困难程度而灰心丧气、止步不前。

就如同我在打算读研究生时想的一样，从那时我就清楚地知道，我并不是为了一个学位，而是希望能够继续学习更多的知识。如今，我再次带着这种心态，虔诚地提交这份博士申请。


## 参考文献




文章我看完了，老师说的是没错的，的确主要思想就是相位体现出对比。

第一部分通过定性和定量的 experiment 证明了在振幅和相位中，相位是更重要的。接着从 template-based contrast computation 的角度说明了为什么相位的正负能够与 saliency 联系起来

第二部分，根据第一部分实证的经验，构建 saliency detector

第三部分就是实证对比。 

清楚了一些，还有许多不清楚，我又找了几篇文章，继续看看，摸一下这条 literature 的路数


