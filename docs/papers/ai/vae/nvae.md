# NVAE: A Deep Hierarchical Variational Autoencoder

Arash Vahdat<sup>1</sup>, Jan Kautz<sup>1</sup>, ***NeurIPS***, 2020

1. *Nvidia*

VAE 最大化 input 和 latent variable 之间的互信息，




## 背景：深度生成模型的竞争格局

在理解NVAE的优势之前，我们需要了解当时主要的基于似然的深度生成模型框架：

### 1. Normalizing Flows (归一化流)

**核心思想**：通过一系列可逆变换将简单分布（如高斯分布）映射到复杂的数据分布。

**数学原理**：
$$x = f_K \circ f_{K-1} \circ \cdots \circ f_1(z)$$

其中 $z \sim p(z)$ 是简单分布，$f_i$ 是可逆函数。根据变量变换公式：

$$\log p(x) = \log p(z) + \sum_{i=1}^K \log \left| \det \frac{\partial f_i}{\partial f_{i-1}} \right|$$

**优势**：
- 精确的似然计算（无需近似）
- 精确的采样过程
- 理论上可以表示任意复杂分布

**劣势**：
- 可逆性约束限制了网络架构设计
- 雅可比行列式计算开销大
- 难以处理高维数据（如高分辨率图像）

**典型模型**：Real NVP, Glow, Flow++

### 2. Autoregressive Models (自回归模型)

**核心思想**：将联合分布分解为条件分布的乘积，按顺序生成每个维度。

**数学原理**：
$$p(x) = \prod_{i=1}^d p(x_i | x_{<i})$$

其中 $x_{<i} = \{x_1, x_2, \ldots, x_{i-1}\}$ 表示前 $i-1$ 个维度。

**优势**：
- 精确的似然计算
- 理论上可以建模任意分布
- 训练稳定

**劣势**：
- **串行采样**：生成速度慢，必须逐个维度生成
- 对数据排序敏感（像素顺序会影响性能）
- 难以学习全局结构

**典型模型**：PixelCNN, PixelRNN, WaveNet

### 3. Deep Energy-Based Models (深度能量模型)

**核心思想**：通过能量函数定义非归一化概率分布。

**数学原理**：
$$p_\theta(x) = \frac{e^{-E_\theta(x)}}{Z(\theta)}$$

其中 $E_\theta(x)$ 是能量函数，$Z(\theta) = \int e^{-E_\theta(x)} dx$ 是配分函数。

**训练方法**：
- **对比散度 (Contrastive Divergence)**
- **Score Matching**：避免计算配分函数
- **MCMC采样**：用于生成样本

**优势**：
- 网络架构灵活性高
- 可以建模复杂分布
- 不需要可逆性约束

**劣势**：
- **配分函数难以计算**：似然计算困难
- **采样困难**：需要MCMC等迭代采样方法
- 训练不稳定，容易模式崩塌

**典型模型**：Restricted Boltzmann Machines, 基于Score的生成模型

### 4. 各框架对比总结

| 模型类型 | 似然计算 | 采样速度 | 架构灵活性 | 训练稳定性 |
|----------|----------|----------|------------|------------|
| **Normalizing Flows** | ✅ 精确 | ✅ 快速 | ❌ 受限 | ✅ 稳定 |
| **Autoregressive** | ✅ 精确 | ❌ 慢 | ✅ 灵活 | ✅ 稳定 |
| **Energy-Based** | ❌ 困难 | ❌ 慢 | ✅ 灵活 | ❌ 不稳定 |
| **VAE** | ⚠️ 近似 | ✅ 快速 | ✅ 灵活 | ✅ 稳定 |

## VAE的独特优势

从上述比较可以看出，VAE在2020年时具有独特的优势组合：

1. **快速采样**：$x = \text{Decoder}(z), z \sim \mathcal{N}(0,I)$，一步生成
2. **易于编码**：编码器网络 $q_\phi(z|x)$ 提供了数据到潜空间的直接映射
3. **架构灵活**：编码器和解码器可以使用任意神经网络架构
4. **训练稳定**：基于变分下界的训练目标相对稳定

**VAE的劣势**：
- 似然是下界估计（不是精确值）
- 生成质量历史上不如GAN
- 后验坍塌问题

## VAE的特殊网络架构需求

虽然VAE有诸多优势，但它对网络架构有着与其他深度学习任务**根本不同**的要求：

### 1. 信息保留 vs. 信息丢弃

**VAE的要求**：最大化输入和潜变量之间的**互信息** $I(X; Z)$
$$I(X; Z) = \mathbb{E}_{p(x,z)}[\log \frac{p(x,z)}{p(x)p(z)}]$$

- VAE需要网络**尽可能保留输入数据的信息内容**
- 编码器必须将所有重要信息压缩到潜变量中
- 解码器必须能从潜变量恢复所有细节

**对比分类网络**：
- 分类网络的目标是**丢弃不相关信息**，只保留类别相关特征
- 例如：识别猫时，具体的毛色、姿态等细节可以丢弃
- VAE则必须保留这些细节用于重构

### 2. 过参数化的不同影响

**解码器过参数化的问题**：
$$\log p(x) = \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] - \text{KL}[q_\phi(z|x) \| p(z)]$$

- 边际对数似然 $\log p(x)$ 只依赖于**生成模型**（解码器）
- 解码器过参数化可能导致**过拟合**，伤害测试集上的对数似然
- 过强的解码器可能"记住"训练数据，而不是学习真实分布

**编码器过参数化的益处**：
- 强大的编码器可以减少**摊销差距** (amortization gap)
- 摊销差距：$\mathbb{E}_{p(x)}[\text{KL}[q_\phi(z|x) \| p_\theta(z|x)]]$
- 更好的编码器 $q_\phi(z|x)$ 能更好地近似真实后验 $p_\theta(z|x)$

> **实验观察**：Wu等人发现，用非编码器方法（如MCMC）估计的边际似然对编码器过拟合不敏感，证实了这一点。

### 3. 长程相关性建模

**VAE的挑战**：
- 数据中存在**长程相关性** (long-range correlations)
- 例如：图像中远距离像素的依赖关系、时间序列中的长期趋势

**架构要求**：
- 网络需要**大感受野** (large receptive fields)
- 能够捕捉全局结构和远程依赖
- 这与分类任务的局部特征关注形成对比

### 4. KL散度无界性带来的训练不稳定

**问题根源**：
$$\text{KL}[q_\phi(z|x) \| p(z)] = \mathbb{E}_{q_\phi(z|x)}[\log q_\phi(z|x) - \log p(z)]$$

- KL散度是**无界的**：$\text{KL}[q \| p] \in [0, +\infty)$
- 在深度层次化VAE中，多层KL项可能导致梯度爆炸
- 训练过程容易不稳定

**传统解决方案的问题**：
- 当时的SOTA VAE模型**省略批量归一化** (Batch Normalization)
- 原因：BN引入的**随机性**可能放大训练不稳定性
- BN的移动平均统计量在VAE训练中可能产生意外的随机波动

### 5. NVAE的架构创新意义

基于以上分析，NVAE的创新就显得格外重要：

1. **信息保留**：层次化架构确保信息在多尺度上得到保留
2. **平衡参数化**：精心设计编码器-解码器平衡
3. **长程依赖**：残差连接和多尺度特征融合
4. **训练稳定**：改进的BN和谱归一化技术

## NVAE的历史意义

NVAE (Nouveau VAE) 是NVIDIA在2020年提出的深度层次化变分自编码器，专门为高分辨率图像生成而设计。NVAE在当时是第一个能够在高分辨率图像上取得与GAN相当生成质量的VAE模型，**证明了VAE框架在保持其固有优势的同时，通过专门的架构设计能够实现高质量的图像生成**。

拟南芥

## 核心创新

### 1. 深度层次化架构 (Deep Hierarchical Architecture)

NVAE采用多层次的潜变量结构，每一层都有自己的潜变量：

$$z = \{z_1, z_2, \ldots, z_L\}$$

其中每一层的潜变量具有不同的空间分辨率，从低分辨率到高分辨率逐层递增。

#### 粗细概念的定义

在NVAE中，"粗"和"细"是按照**空间分辨率**和**抽象程度**来定义的：

- **粗 (Coarse)**：低分辨率、高抽象级别的潜变量（如 $z_1$：全局语义信息）
- **细 (Fine)**：高分辨率、低抽象级别的潜变量（如 $z_L$：局部细节信息）

**层次结构示例**：
```
z_1: 1×1×512    (最粗 - 全局语义：物体类别、整体布局)
z_2: 4×4×256    (中等 - 区域信息：主要部件、颜色分布)  
z_3: 16×16×128  (中等 - 局部结构：边缘、纹理模式)
z_L: 64×64×64   (最细 - 细节信息：像素级细节、噪声)
```

#### 生成过程：由粗到细 (Top-down Generation)

**数学表达**：
$$p_\theta(x, z) = p(z_1) \prod_{i=2}^L p_\theta(z_i | z_{<i}) \cdot p_\theta(x | z)$$

**生成流程**：
1. **从最粗层开始**：$z_1 \sim p(z_1) = \mathcal{N}(0, I)$
2. **逐层细化**：$z_2 | z_1$, $z_3 | z_1, z_2$, ..., $z_L | z_1, \ldots, z_{L-1}$
3. **最终生成图像**：$x | z_1, \ldots, z_L$

**为什么叫Top-down？**
- **Top**：抽象级别高的粗层（全局语义）
- **Down**：向抽象级别低的细层传递（局部细节）
- 模拟人类认知：先确定"这是一张脸"，再逐步添加"眼睛"、"鼻子"等细节

#### 推理过程：由细到粗 (Bottom-up Inference)

**数学表达**：
$$q_\phi(z|x) = \prod_{i=1}^L q_\phi(z_i | x, z_{>i})$$

其中 $q(z_{<l}|x) := \prod_{i=1}^{l-1} q(z_i|x, z_{<i})$ 是前 $(l-1)$ 层的近似后验。

**推理流程**：
1. **从输入图像开始**：观察到完整的像素信息
2. **先推断细节层**：$z_L | x$（从像素推断局部细节）
3. **逐层抽象**：$z_{L-1} | x, z_L$, ..., $z_1 | x, z_2, \ldots, z_L$
4. **最终得到全局表示**：$z_1$（最抽象的语义表示）

**为什么叫Bottom-up？**
- **Bottom**：具体的像素信息（最底层）
- **Up**：向抽象的语义表示上升
- 模拟感知过程：从像素细节逐步抽象出高层语义

#### 网络架构实现

根据论文图2，NVAE使用两个网络：

##### (a) Bidirectional Encoder - 双向编码器

**Bottom-up路径**（自下而上）：
```
输入图像 x
    ↓ (卷积+下采样)
低级特征 → z_L 推断
    ↓ (继续抽象)  
中级特征 → z_{L-1} 推断
    ↓
高级特征 → z_1 推断
```

**Top-down路径**（自上而下）：
```
高级特征
    ↓ (上采样+融合)
与中级特征融合 → 改进 z_{L-1}
    ↓
与低级特征融合 → 改进 z_L
```

**为什么需要双向？**
- **Bottom-up**：从像素提取层次化特征
- **Top-down**：用高层语义信息指导低层细节推断
- **结合**：让每层都能利用全局和局部信息

##### (b) Generative Model - 生成模型

**Top-down生成**：
```
z_1 (全局语义)
    ↓ (上采样+条件生成)
z_2 | z_1 (区域信息)
    ↓
z_3 | z_1, z_2 (局部结构)
    ↓
x | z_1, ..., z_L (最终图像)
```

#### 关键设计细节

**重参数化技巧**：每层使用独立的重参数化
$$z_i = \mu_i(z_{<i}) + \sigma_i(z_{<i}) \odot \epsilon_i, \quad \epsilon_i \sim \mathcal{N}(0, I)$$

**特征融合**：
- 使用残差连接 $r$ 和特征组合 $\oplus$
- 可训练参数 $h$ 控制融合权重

**计算复杂度优化**：
- **双向推理**：重用生成模型的top-down网络进行推理
- 避免为编码器单独构建top-down网络

### 2. 残差正态耦合层 (Residual Normal Coupling Layers)

NVAE引入了残差连接的正态耦合层来增强潜变量的表达能力：

$$z_{i+1} = z_i + f_\theta(z_i)$$

其中 $f_\theta$ 是可学习的变换函数，这种设计允许模型学习更复杂的潜变量分布。

### 3. 批量归一化 (Batch Normalization) 的改进

NVAE提出了专门针对VAE的批量归一化技术，解决了传统BN在VAE训练中的不稳定问题：

- **解耦的BN参数**：为编码器和解码器使用独立的BN参数
- **渐进式训练**：在训练初期禁用某些BN层，逐步启用

### 4. 谱归一化 (Spectral Normalization)

为了稳定训练，NVAE在编码器和解码器的关键层使用谱归一化：

$$W_{SN} = \frac{W}{\sigma(W)}$$

其中 $\sigma(W)$ 是权重矩阵 $W$ 的最大奇异值。

## 损失函数

NVAE使用标准的VAE损失函数，但针对层次化结构进行了扩展：

$$\mathcal{L} = \mathbb{E}_{q_\phi(z|x)}[-\log p_\theta(x|z)] + \sum_{i=1}^L \text{KL}(q_\phi(z_i|x, z_{>i}) \| p_\theta(z_i|z_{<i}))$$

包含：
- **重构损失**：确保生成图像与原图像相似
- **多层KL散度**：每一层潜变量都有对应的正则化项

## 训练技巧

### 1. 渐进式训练 (Progressive Training)

- 从低分辨率开始训练
- 逐步增加图像分辨率
- 每个分辨率级别都有对应的潜变量层

### 2. 平衡KL项

使用KL退火和自由位 (free bits) 技术平衡重构损失和KL散度：

$$\mathcal{L}_{KL} = \sum_{i=1}^L \max(\text{KL}_i, \lambda \cdot d_i)$$

其中 $\lambda$ 是自由位参数，$d_i$ 是第 $i$ 层潜变量的维度。

### 3. 预训练策略

NVAE采用分阶段预训练：
1. 首先训练较浅的网络
2. 逐步增加网络深度
3. 精细调整所有参数

## 实验结果

### 性能指标

在多个数据集上的表现：

| 数据集 | FID ↓ | IS ↑ | Precision | Recall |
|--------|-------|------|-----------|--------|
| CIFAR-10 | 7.36 | 8.9 | 0.78 | 0.54 |
| CelebA-HQ 256×256 | 32.9 | - | 0.69 | 0.42 |
| FFHQ 256×256 | 52.1 | - | 0.64 | 0.35 |

### 与其他模型比较

- **相比传统VAE**：显著提升了图像生成质量
- **相比GAN**：在某些指标上接近GAN的性能
- **训练稳定性**：比GAN更稳定，不存在模式崩塌问题

## 网络架构细节

### 编码器架构

```
输入图像 (3×256×256)
    ↓
Conv Block + Down (64×128×128)
    ↓
Residual Blocks + Down (128×64×64)
    ↓
Residual Blocks + Down (256×32×32)
    ↓
...
    ↓
潜变量层 z_L (512×1×1)
```

### 解码器架构

```
潜变量 z_1 (512×1×1)
    ↓
Residual Blocks + Up (256×32×32)
    ↓
与编码器特征融合
    ↓
Residual Blocks + Up (128×64×64)
    ↓
...
    ↓
输出图像 (3×256×256)
```

## 技术优势

1. **可解释性**：相比GAN，VAE提供了明确的概率解释
2. **稳定训练**：不会出现模式崩塌等GAN常见问题
3. **潜空间平滑**：支持连续的潜空间插值
4. **条件生成**：容易扩展到条件生成任务

## 局限性

1. **生成质量**：虽然大幅改进，但在某些细节上仍不如最先进的GAN
2. **计算复杂度**：深度层次化结构带来较高的计算开销
3. **超参数敏感**：需要仔细调整各层的平衡参数

## 影响与应用

NVAE的提出证明了VAE在高分辨率图像生成上的潜力，为后续的层次化生成模型研究奠定了基础，并影响了VQ-VAE2、DDPM等后续工作的设计思路。