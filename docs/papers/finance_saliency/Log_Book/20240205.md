# Hyper ridge gamma and K-fold

## Hyper ridge gamma

对于 ridge 超参数的选取，与李煌师兄简单讨论了一下后，觉得并不适用 K-fold。例如将十年数据分为 5-fold，使用八年的数据 train，两年的数据 valid，此时流程为：

1. 使用八年的 train data 进行 ridge 回归得到风险价格 $b$
2. 使用两年的 valid data 利用 $b$ 进行频率协方差分解计算

> 注意，此时 train data 并没有进行频率计算，而 valid data 也没有进行风险价格的计算。

然而，频率分解要求最少五年的数据，因此，计算 valid 步骤所需的数据量非常大，并且逻辑上有所不通。因此，在优化过程中并没有使用 k-fold，而是采用了如下算法：

1. 在 $t$ 时间节点，使用过去六年至过去一年数据 ($t-72 \sim t-13$) 做 ridge 回归得到风险价格 $b$ 
2. 基于第一步得到的风险价格，在 $t-12 \sim t-1$ 的每个时点，使用过去五年数据进行频率分解计算多因子频率
3. 在 $t-12 \sim t-1$ 的每个时点，根据得到的频率进行 sort 构造组合，计算夏普比率
4. 选择夏普比率最高的组合对应的超参数 gamma，在 test data 上计算构造组合

然而，目前这个过程跑的非常之慢，原本不设置任何超参数的情况下大约 20 分钟跑完从 1958-2018 的数据，现在最外层循环为 gamma 循环，初始设置了从 0.01-0.001 中的等间距 20 个数，内层循环是验证集每个时点的频率分解计算，总共计算 12 次，因此，现在的运算时长是原来的 240 倍，也就是 80 个小时，这无疑是行不通的。

于是我现在把超参数的选择设置为从 0.01-0.001 总共 5 个数，valid 为半年，整体数据时长从 1995 年开始，明天早上看看结果。

## K-fold ridge gamma


### 估计流程

原先以为超参数的选取标准应该是哪一个风险价格有更好的夏普比率表现，经老师提醒后应该为 ridge gamma 应该只与回归效果有关，如果 ridge 回归效果好不能使得结果好，那么是就应该再进一步提升回归方法，而不应该以夏普比率为导向。

1. 在 $t$ 时间点选取过去五年的股票数据，进行 5-fold，四年为 train，一年为 valid
2. 在 train data 中，选择缺失值不多于两年的股票，计算其均值和与因子的协方差，基于所有的 ridge 超参数回归得到风险价格 $b$
3. 将所有超参数对应的风险价格 $b$，在 valid data 中使用，计算 $R$ 方，并选择最优结果对应的超参数
4. 选择该超参数进行频率计算


### Results

经过调整后，代码结果如下，非常接近于原来的结果，略有下降：

<div class = 'centertable'>

|           | CAPM             | FF3                | FF5                | FF5 + Momentum     |
|:----------|:-----------------|:-------------------|:-------------------|:-------------------|
| Intercept | 0.3***<br>(0.1)  | 0.22**<br>(0.1)    | 0.26**<br>(0.11)   | 0.33***<br>(0.11)  |
| mktrf     | -0.05*<br>(0.03) | -0.09***<br>(0.03) | -0.09***<br>(0.03) | -0.11***<br>(0.03) |
| smb       |                | 0.26***<br>(0.06)  | 0.23***<br>(0.07)  | 0.24***<br>(0.07)  |
| hml       |                | 0.11<br>(0.07)     | 0.1<br>(0.1)       | 0.05<br>(0.09)     |
| rmw       |                |                  | -0.14<br>(0.09)    | -0.12<br>(0.08)    |
| cma       |                |                  | 0.03<br>(0.12)     | 0.06<br>(0.11)     |
| umd       |                |                  |                  | -0.09**<br>(0.04)  |
| Adj. R2   | 0.01             | 0.11               | 0.13               | 0.15               |

</div>

甚至略有下降，以下为原有结果，当固定 ridge 超参数为 0.0001 时。


<div class="centertable">

|           | CAPM             | FF3               | FF5                | FF5 + Momentum     |
|:----------|:-----------------|:------------------|:-------------------|:-------------------|
| Intercept | 0.31***<br>(0.1) | 0.25**<br>(0.1)   | 0.3**<br>(0.12)    | 0.37***<br>(0.13)  |
| mktrf     | -0.05*<br>(0.03) | -0.1***<br>(0.03) | -0.12***<br>(0.03) | -0.13***<br>(0.03) |
| smb       |                | 0.3***<br>(0.06)  | 0.27***<br>(0.06)  | 0.27***<br>(0.06)  |
| hml       |                | 0.04<br>(0.08)    | 0.05<br>(0.09)     | -0.0<br>(0.09)     |
| rmw       |                |                 | -0.16*<br>(0.08)   | -0.14*<br>(0.07)   |
| cma       |                |                 | -0.0<br>(0.13)     | 0.03<br>(0.12)     |
| umd       |                |                 |                  | -0.1*<br>(0.05)    |
| Adj. R2   | 0.01             | 0.12              | 0.13               | 0.15               |
</div>

接下来具体看一下超参数的选取情况和验证集 $R$ 方估计量：

#### 超参数

超参数的范围设置是从 0.01-0.0001 等距离 20 个数，选取频率如下，可以看到要么比较大，要么比较小，范围比较极化

<div align ='center'>

![](../work_img/20240207P1.png)
</div>

#### 验证集 $R$ 方

<div align ='center'>

![](../work_img/20240207P2.png)
</div>



### Plan

目前还有的改进方向就是将 ridge 回归的显著性考虑进去，例如将不显著的因子去除，但是这个并不如我想象中简单。

有如下说法，通过惩罚回归得到的系数是显著有偏的，因此在这种情况下计算标准误没什么意义

> Standard errors are not very meaningful for strongly biased estimates such as arise from penalized estimation methods.
>
> Penalized estimation is a procedure that reduces the variance of estimators by introducing **substantial bias**.

在大多数情况下，根本无法得到这种 bias 的估计。在实际操作中，介绍了一种 bootstrap 方法，文章如下：

> Capur M. Bootstrap estimation of standard error of ridge estimates[J]. 2006.

但是话说回来，ridge 方法本身已经对回归系数进行了惩罚，不显著的系数可能值已经变得很小了，这样做不确定是否还有意义。

根据现有的报告，超参数对于主要实验结果影响不大，均是 $\alpha$ 弱于单频率分解因子，但是呈现出的效果是当解释因子越多，$\alpha$ 反而越显著，这一点十分 robust。

个人认为，目前值得研究的问题是，频率因子的本质是什么，也许只有知道了这一点，才能将现有的实验结果融会贯通。

















